# nGinx badbot blocking config script by QWeb Ltd.
#
# Identifies bots known for either aggressive content scraping or malicious activity, and responds to their requests with HTTP 403s instead of allowing them to consume further server resources. This is basically just a list of AI/LLM scrapers.
# Note that we've purposefully excluded some bots from this list, despite their use for AI/LLMs, because they're also used for search indexing and SEO tools and blocking their access entirely wouldn't be wise.
#
# It's recommended that you use this script together with our rate limiting config at https://github.com/qwebltd/Useful-scripts/blob/main/Bash%20scripts%20for%20Linux/nginx-rate-limiting.conf
# It's also recommended that you uses Fail2Ban to subsequently firewall IPs that incur multiple 403s in quick succession, to nuke badbot requests completely.
#
# Simply add this file to your nginx config directory, for example /etc/nginx/plesk.conf.d/ip_default/nginx-badbot-forbids.conf on a Plesk server.
# You'll need to copy the content of the server block to the start of your vhost's own server block. Or, with Plesk, the beginning of the Additional nginx directives field.
#
# Don't forget to reload nginx after adding or editing this file! For example, on Systemd based systems, e.g. CentOS / Redhat / Rocky / Alma etc:
# sudo systemctl reload nginx
#
# Refer to the nGinx config documentation for how this works:
#  https://nginx.org/en/docs/http/ngx_http_map_module.html
#
# Requires ngx_http_map_module and nGinx 1.0.4 or above: https://nginx.org/en/docs/http/ngx_http_map_module.html
#
#
#

map $http_user_agent $known_badbots {
	default 0;
	~*(AI2Bot|Anthropic|BrightBot|ByteDance|ByteSpider|CCBot|ChatGPT|ClaudeBot|Claude-Web|Cohere-AI|Cohere-Training-Data-Crawler|DiffBot|DuckAssistBot|FriendlyCrawler|Friendly_Crawler|Google-CloudVertexBot|GPTBot|ICC-Crawler|Img2Dataset|Kangaroo\ Bot|MLBot|OAI-SearchBot|PanguBot|Sentibot|VelenPublicWebCrawler|Webzio-Extended) 1;
}

server {
	if ($known_badbots) {
		return 403;
	}
}
